{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e883dbb5",
   "metadata": {},
   "source": [
    "# PROGRES - TME2\n",
    "\n",
    "Fabien Mathieu - fabien.mathieu@normalesup.org\n",
    "\n",
    "Sébastien Tixeuil - Sebastien.Tixeuil@lip6.fr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c257dd",
   "metadata": {},
   "source": [
    "**Note**: \n",
    "- Star exercises (indicated by *) should only be done if all other exercises have been completed. You \n",
    "don't have to do them if you do not want."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e22d148",
   "metadata": {},
   "source": [
    "# Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f5b10f",
   "metadata": {},
   "source": [
    "1. Cite your sources\n",
    "2. One file to rule them all\n",
    "3. Explain\n",
    "4. Execute your code\n",
    "\n",
    "\n",
    "https://github.com/balouf/progres/blob/main/rules.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972a6ebb",
   "metadata": {},
   "source": [
    "# Exercice 1 - Regular Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73463220",
   "metadata": {},
   "source": [
    "Consider the following list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c3d73fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:31.166734Z",
     "start_time": "2024-10-11T07:03:31.162693Z"
    }
   },
   "outputs": [],
   "source": [
    "L = ['marie.Dupond@gmail.com', 'lucie.Durand@wanadoo.fr', \n",
    "'Sophie.Parmentier @@ gmail.com', 'franck.Dupres.gmail.com', \n",
    "'pierre.Martin@lip6 .fr ',' eric.Deschamps@gmail.com '] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b01f4c1",
   "metadata": {},
   "source": [
    "- Which of these entries are valid?\n",
    "- Use regular expressions to identify valid *gmail* addresses and display them. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea43648",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ca98ad",
   "metadata": {},
   "source": [
    "The valid entries are..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be212147",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:31.182237Z",
     "start_time": "2024-10-11T07:03:31.167743Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import re \n",
    "M = []\n",
    "def true_gmail(mail_list):\n",
    "    for i in range(len(L)):\n",
    "        m = re.search('^[ a-zA-Z0-9._%+-]+@gmail\\.com', L[i])\n",
    "        if m:\n",
    "            M.append(L[i])\n",
    "    return M\n",
    "\n",
    "#https://docs.python.org/es/3/library/re.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01daac63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:31.210273Z",
     "start_time": "2024-10-11T07:03:31.196497Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['marie.Dupond@gmail.com', 'eric.Deschamps@gmail.com']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Valid emails: \", true_gmail(L))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667779f5",
   "metadata": {},
   "source": [
    "- Use regular expressions to check if a string ends with a number. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b88846",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c39ba330",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:31.221802Z",
     "start_time": "2024-10-11T07:03:31.211282Z"
    }
   },
   "outputs": [],
   "source": [
    "def ends_with_number(txt):\n",
    "    txt = re.search('\\d$', txt)\n",
    "    if txt:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a08cff77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:31.246076Z",
     "start_time": "2024-10-11T07:03:31.235381Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ends_with_number('to42to'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf95e0b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:31.257782Z",
     "start_time": "2024-10-11T07:03:31.248084Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ends_with_number('to42to666'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa6debe",
   "metadata": {},
   "source": [
    "- Use regular expressions to remove problematic zeros from an IPv4 address expressed as a \n",
    "string. (example: \"216.08.094.196\" should become \"216.8.94.196\", but \"216.80.140.196\" \n",
    "should remain \"216.80.140.196\"). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e53de2a",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44630bc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:31.271323Z",
     "start_time": "2024-10-11T07:03:31.261798Z"
    }
   },
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/58013274/python-remove-leading-zeros-from-ip-addresses\n",
    "def normalize_ip(txt):\n",
    "    aux = re.sub('(^|\\.)0+(?=[^.])', r'\\1', txt)\n",
    "    return aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5f47bb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:31.295246Z",
     "start_time": "2024-10-11T07:03:31.284633Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'216.0.94.196'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(normalize_ip(\"216.0.094.196\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a25cc6c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:31.309262Z",
     "start_time": "2024-10-11T07:03:31.296255Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'216.8.94.196'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(normalize_ip(\"216.08.094.196\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63cd3133",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:31.350525Z",
     "start_time": "2024-10-11T07:03:31.313271Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'216.80.140.196'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(normalize_ip(\"216.80.140.196\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b75dd4",
   "metadata": {},
   "source": [
    "- Use regular expressions to transform a date from MM-DD-YYYY format to DD-MM-YYYY \n",
    "format. (example \"11-06-2020\" should become \"06-11-2020\"). Optionally*, do the same thing using the `datetime` package."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde678ab",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a34722a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:31.360858Z",
     "start_time": "2024-10-11T07:03:31.356546Z"
    }
   },
   "outputs": [],
   "source": [
    "#https://www.progress.com/es/blogs/formato-de-fecha-en-python\n",
    "from datetime import datetime\n",
    "def switch_md(txt):\n",
    "    aux = re.sub('(\\d{2})-(\\d{2})-(\\d{4})', r'\\2-\\1-\\3', txt)\n",
    "    return aux\n",
    "    \n",
    "def switch_md_datetime(txt):\n",
    "    txt = datetime.strptime(txt, '%m-%d-%Y')\n",
    "    return txt.strftime('%d-%m-%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3ae257c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:31.399470Z",
     "start_time": "2024-10-11T07:03:31.386752Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'06-11-2020'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(switch_md(\"11-06-2020\"))\n",
    "print(switch_md_datetime(\"11-06-2020\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548ba2b8",
   "metadata": {},
   "source": [
    "# Exercice 2 - Analyze XML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3174ab",
   "metadata": {},
   "source": [
    "- Write a Python code that retrieves the content of the page at:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03142481",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:31.410291Z",
     "start_time": "2024-10-11T07:03:31.400475Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<CATALOG>\\n  <CD>\\n    <TITLE>Empire Burlesque</TITLE>\\n    <ARTIST>Bob Dylan</ARTIST>\\n    <COUNTRY>USA</COUNTRY>\\n    <COMPANY>Columbia</COMPANY>\\n    <PRICE>10.90</PRICE>\\n    <YEAR>1985</YEAR>\\n  </CD>\\n  <CD>\\n    <TITLE>Hide your heart</TITLE>\\n    <ARTIST>Bonnie Tyler</ARTIST>\\n    <COUNTRY>UK</COUNTRY>\\n    <COMPANY>CBS Records</COMPANY>\\n    <PRICE>9.90</PRICE>\\n    <YEAR>1988</YEAR>\\n  </CD>\\n  <CD>\\n    <TITLE>Greatest Hits</TITLE>\\n    <ARTIST>Dolly Parton</ARTIST>\\n    <COUNTRY>USA</COUNTRY>\\n    <COMPANY>RCA</COMPANY>\\n    <PRICE>9.90</PRICE>\\n    <YEAR>1982</YEAR>\\n  </CD>\\n  <CD>\\n    <TITLE>Still got the blues</TITLE>\\n    <ARTIST>Gary Moore</ARTIST>\\n    <COUNTRY>UK</COUNTRY>\\n    <COMPANY>Virgin records</COMPANY>\\n    <PRICE>10.20</PRICE>\\n    <YEAR>1990</YEAR>\\n  </CD>\\n  <CD>\\n    <TITLE>Eros</TITLE>\\n    <ARTIST>Eros Ramazzotti</ARTIST>\\n    <COUNTRY>EU</COUNTRY>\\n    <COMPANY>BMG</COMPANY>\\n    <PRICE>9.90</PRICE>\\n    <YEAR>1997</YEAR>\\n  </CD>\\n  <CD>\\n    <TITLE>One night only</TITLE>\\n    <ARTIST>Bee Gees</ARTIST>\\n    <COUNTRY>UK</COUNTRY>\\n    <COMPANY>Polydor</COMPANY>\\n    <PRICE>10.90</PRICE>\\n    <YEAR>1998</YEAR>\\n  </CD>\\n  <CD>\\n    <TITLE>Sylvias Mother</TITLE>\\n    <ARTIST>Dr.Hook</ARTIST>\\n    <COUNTRY>UK</COUNTRY>\\n    <COMPANY>CBS</COMPANY>\\n    <PRICE>8.10</PRICE>\\n    <YEAR>1973</YEAR>\\n  </CD>\\n  <CD>\\n    <TITLE>Maggie May</TITLE>\\n    <ARTIST>Rod Stewart</ARTIST>\\n    <COUNTRY>UK</COUNTRY>\\n    <COMPANY>Pickwick</COMPANY>\\n    <PRICE>8.50</PRICE>\\n    <YEAR>1990</YEAR>\\n  </CD>\\n  <CD>\\n    <TITLE>Romanza</TITLE>\\n    <ARTIST>Andrea Bocelli</ARTIST>\\n    <COUNTRY>EU</COUNTRY>\\n    <COMPANY>Polydor</COMPANY>\\n    <PRICE>10.80</PRICE>\\n    <YEAR>1996</YEAR>\\n  </CD>\\n  <CD>\\n    <TITLE>When a man loves a woman</TITLE>\\n    <ARTIST>Percy Sledge</ARTIST>\\n    <COUNTRY>USA</COUNTRY>\\n    <COMPANY>Atlantic</COMPANY>\\n    <PRICE>8.70</PRICE>\\n    <YEAR>1987</YEAR>\\n  </CD>\\n  <CD>\\n    <TITLE>Black angel</TITLE>\\n    <ARTIST>Savage Rose</ARTIST>\\n    <COUNTRY>EU</COUNTRY>\\n    <COMPANY>Mega</COMPANY>\\n    <PRICE>10.90</PRICE>\\n    <YEAR>1995</YEAR>\\n  </CD>\\n  <CD>\\n    <TITLE>1999 Grammy Nominees</TITLE>\\n    <ARTIST>Many</ARTIST>\\n    <COUNTRY>USA</COUNTRY>\\n    <COMPANY>Grammy</COMPANY>\\n    <PRICE>10.20</PRICE>\\n    <YEAR>1999</YEAR>\\n  </CD>\\n  <CD>\\n    <TITLE>For the good times</TITLE>\\n    <ARTIST>Kenny Rogers</ARTIST>\\n    <COUNTRY>UK</COUNTRY>\\n    <COMPANY>Mucik Master</COMPANY>\\n    <PRICE>8.70</PRICE>\\n    <YEAR>1995</YEAR>\\n  </CD>\\n  <CD>\\n    <TITLE>Big Willie style</TITLE>\\n    <ARTIST>Will Smith</ARTIST>\\n    <COUNTRY>USA</COUNTRY>\\n    <COMPANY>Columbia</COMPANY>\\n    <PRICE>9.90</PRICE>\\n    <YEAR>1997</YEAR>\\n  </CD>\\n  <CD>\\n    <TITLE>Tupelo Honey</TITLE>\\n    <ARTIST>Van Morrison</ARTIST>\\n    <COUNTRY>UK</COUNTRY>\\n    <COMPANY>Polydor</COMPANY>\\n    <PRICE>8.20</PRICE>\\n    <YEAR>1971</YEAR>\\n  </CD>\\n  <CD>\\n    <TITLE>Soulsville</TITLE>\\n    <ARTIST>Jorn Hoel</ARTIST>\\n    <COUNTRY>Norway</COUNTRY>\\n    <COMPANY>WEA</COMPANY>\\n    <PRICE>7.90</PRICE>\\n    <YEAR>1996</YEAR>\\n  </CD>\\n  <CD>\\n    <TITLE>The very best of</TITLE>\\n    <ARTIST>Cat Stevens</ARTIST>\\n    <COUNTRY>UK</COUNTRY>\\n    <COMPANY>Island</COMPANY>\\n    <PRICE>8.90</PRICE>\\n    <YEAR>1990</YEAR>\\n  </CD>\\n  <CD>\\n    <TITLE>Stop</TITLE>\\n    <ARTIST>Sam Brown</ARTIST>\\n    <COUNTRY>UK</COUNTRY>\\n    <COMPANY>A and M</COMPANY>\\n    <PRICE>8.90</PRICE>\\n    <YEAR>1988</YEAR>\\n  </CD>\\n  <CD>\\n    <TITLE>Bridge of Spies</TITLE>\\n    <ARTIST>T\\'Pau</ARTIST>\\n    <COUNTRY>UK</COUNTRY>\\n    <COMPANY>Siren</COMPANY>\\n    <PRICE>7.90</PRICE>\\n    <YEAR>1987</YEAR>\\n  </CD>\\n  <CD>\\n    <TITLE>Private Dancer</TITLE>\\n    <ARTIST>Tina Turner</ARTIST>\\n    <COUNTRY>UK</COUNTRY>\\n    <COMPANY>Capitol</COMPANY>\\n    <PRICE>8.90</PRICE>\\n    <YEAR>1983</YEAR>\\n  </CD>\\n  <CD>\\n    <TITLE>Midt om natten</TITLE>\\n    <ARTIST>Kim Larsen</ARTIST>\\n    <COUNTRY>EU</COUNTRY>\\n    <COMPANY>Medley</COMPANY>\\n    <PRICE>7.80</PRICE>\\n    <YEAR>1983</YEAR>\\n  </CD>\\n  <CD>\\n    <TITLE>Pavarotti Gala Concert</TITLE>\\n    <ARTIST>Luciano Pavarotti</ARTIST>\\n    <COUNTRY>UK</COUNTRY>\\n    <COMPANY>DECCA</COMPANY>\\n    <PRICE>9.90</PRICE>\\n    <YEAR>1991</YEAR>\\n  </CD>\\n  <CD>\\n    <TITLE>The dock of the bay</TITLE>\\n    <ARTIST>Otis Redding</ARTIST>\\n    <COUNTRY>USA</COUNTRY>\\n    <COMPANY>Stax Records</COMPANY>\\n    <PRICE>7.90</PRICE>\\n    <YEAR>1968</YEAR>\\n  </CD>\\n  <CD>\\n    <TITLE>Picture book</TITLE>\\n    <ARTIST>Simply Red</ARTIST>\\n    <COUNTRY>EU</COUNTRY>\\n    <COMPANY>Elektra</COMPANY>\\n    <PRICE>7.20</PRICE>\\n    <YEAR>1985</YEAR>\\n  </CD>\\n  <CD>\\n    <TITLE>Red</TITLE>\\n    <ARTIST>The Communards</ARTIST>\\n    <COUNTRY>UK</COUNTRY>\\n    <COMPANY>London</COMPANY>\\n    <PRICE>7.80</PRICE>\\n    <YEAR>1987</YEAR>\\n  </CD>\\n  <CD>\\n    <TITLE>Unchain my heart</TITLE>\\n    <ARTIST>Joe Cocker</ARTIST>\\n    <COUNTRY>USA</COUNTRY>\\n    <COMPANY>EMI</COMPANY>\\n    <PRICE>8.20</PRICE>\\n    <YEAR>1987</YEAR>\\n  </CD>\\n</CATALOG>\\n'\n"
     ]
    }
   ],
   "source": [
    "#check\n",
    "import urllib.request\n",
    "page = urllib.request.urlopen('https://www.w3schools.com/xml/cd_catalog.xml')\n",
    "print(page.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e00a9d",
   "metadata": {},
   "source": [
    "- Look at the text content and load as xml."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df73d97b",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba04b2e",
   "metadata": {},
   "source": [
    "- Write a `display_cd` function that displays (i.e. `print`), for a CD: title, artist, country, company, year.\n",
    "- Display all CDs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe57dc89",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d954b0cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:31.730469Z",
     "start_time": "2024-10-11T07:03:31.712761Z"
    },
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "def display_cd(entry):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcd39fb",
   "metadata": {},
   "source": [
    "- Display all 1980s CDs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c71f431",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dce507",
   "metadata": {},
   "source": [
    "- Display all British CDs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbb8fa8",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e87e805",
   "metadata": {},
   "source": [
    "# Exercice 3 - Analyze JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a857d6",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- Write a Python program that gets the file of filming locations in Paris at:\n",
    "\n",
    "First, we create a session and use a get request on the url to get the filming locations. The response r has the content of the url requested.\n",
    "The response should be parsed into json with r.json() because the GET request returned JSON data, so .json() function allows us to convert that JSON data into a Python object\n",
    "Source: https://www.geeksforgeeks.org/response-json-python-requests/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ec18ba22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:31.786738Z",
     "start_time": "2024-10-11T07:03:31.778307Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12265\n",
      "{'datasetid': 'lieux-de-tournage-a-paris', 'recordid': '0ff321c5b140a12a8e50a1b212a7c5f5bced91d7', 'fields': {'coord_x': 2.37006242, 'id_lieu': '2017-751', 'adresse_lieu': 'rue du faubourg du temple, 75011 paris', 'geo_shape': {'coordinates': [2.370062415669748, 48.8696979988026], 'type': 'Point'}, 'coord_y': 48.869698, 'ardt_lieu': '75011', 'nom_tournage': '2 Fils (Nouvelle Demande Décor Librairie / Journées interverties)', 'nom_realisateur': 'Félix MOATI', 'date_debut': '2017-10-19', 'type_tournage': 'Long métrage', 'annee_tournage': '2017', 'nom_producteur': 'NORD OUEST FILMS', 'date_fin': '2017-10-19', 'geo_point_2d': [48.8696979988026, 2.370062415669748]}, 'geometry': {'type': 'Point', 'coordinates': [2.370062415669748, 48.8696979988026]}, 'record_timestamp': '2024-01-31T13:40:46.402+01:00'}\n"
     ]
    }
   ],
   "source": [
    "from json import load, dump\n",
    "from pathlib import Path\n",
    "from requests import Session\n",
    "\n",
    "url = \"https://opendata.paris.fr/explore/dataset/lieux-de-tournage-a-paris/download/?format=json&timezone=Europe/Berlin&lang=fr\"\n",
    "\n",
    "s = Session()\n",
    "r = s.get(url)\n",
    "\n",
    "if r.status_code == 200:\n",
    "    # Store the JSON data in a variable\n",
    "    locs = r.json()  # Parse the JSON data\n",
    "else:\n",
    "    locs = None\n",
    "\n",
    "print(len(locs))\n",
    "\n",
    "print(locs[0])\n",
    "# print(locs[0].get(\"fields\", \"[Unknown]\").get(\"nom_tournage\", \"[Unknown]\"))\n",
    "# print(type(locs[0]))\n",
    "# print(locs[0].keys())\n",
    "# print(locs[0]['geometry'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237b389d",
   "metadata": {},
   "source": [
    "- How many entries have you got?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5b7b08",
   "metadata": {},
   "source": [
    "We obtained 12265 entries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49770b26",
   "metadata": {},
   "source": [
    "- Analyze the JSON file: what is its structure?\n",
    "- Write a function that converts an entry in a string that shows director, title, district, start date, end date, and geographic coordinates.\n",
    "- Convert all entries in strings (warning: some entries may have issues).\n",
    "- Display the first 20 entries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7211fc3f",
   "metadata": {},
   "source": [
    "From printing some elements in locs, we could see that the json file is made of different dictionaries. Each dictionary belongs to one filming location of a movie in Paris. each dictionary has different key-value pairs that give us details about each filming location. Examples of key-value pairs include: datasetid, recordid, fields, geometry, and record_timestamp which are the keys found at the top level of the json file. These were found by using the keys() function on each object of the list we got.\n",
    "\n",
    "The function wants us to print each entry as a string that shows the values of the following keys:\n",
    "* nom_tournage : for the title of the film\n",
    "* nom_realisateur : for the name of the director\n",
    "* date_debut : for the start date\n",
    "* date_fin : for the end date\n",
    "* ardt_lieu : for the post code\n",
    "* coordinates (in 'geometry' key) : for the geographic coordinates\n",
    "\n",
    "We figured that the function \"get\" in dictionaries help a lot for extracting specific values of keys, especially in cases where some entries are missing some values. This could be handled by using the get function and supplying it with a second parameter which is the value we want to assign to a missing value of an entry. we chose the second parameter to be [Unknown]. This way, if for example a certain entry is missing the name of the director, it would say [unknown] for the director name.\n",
    "\n",
    "Sources we used to manipulate dictionaries more comfortably: <br> https://www.geeksforgeeks.org/handling-missing-keys-python-dictionaries/ <br> https://www.geeksforgeeks.org/iterate-over-a-dictionary-in-python/ <br>\n",
    "https://note.nkmk.me/en/python-dict-keys-values-items/ <br>\n",
    "https://www.w3schools.com/python/python_ref_dictionary.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0540bb3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:35.576923Z",
     "start_time": "2024-10-11T07:03:35.572252Z"
    },
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "def display_loc(entry):\n",
    "    # the entry is a dictionary.\n",
    "    # we extract the key values that we are interested in printing, namely: title, director, start and end dates, post code, and coordinates.\n",
    "    title=entry.get(\"fields\", \"[Unknown]\").get(\"nom_tournage\", \"[Unknown]\")\n",
    "    director=entry.get(\"fields\", \"[Unknown]\").get(\"nom_realisateur\", \"[Unknown]\")\n",
    "    start_date=entry.get(\"fields\", \"[Unknown]\").get(\"date_debut\", \"[Unknown]\")\n",
    "    end_date=entry.get(\"fields\", \"[Unknown]\").get(\"date_fin\", \"[Unknown]\")\n",
    "    code=entry.get(\"fields\", \"[Unknown]\").get(\"ardt_lieu\", \"[Unknown]\")\n",
    "    coordinates=entry.get(\"geometry\", \"[Unknown]\").get(\"coordinates\", \"[Unknown]\")\n",
    "    # separating the coordinates array that we get into two elements and handling the case where the value of the key \"coordinates\" is unknown or missing from our dictionary\n",
    "    if(coordinates!=\"[Unknown]\"):\n",
    "        coordinate1=str(coordinates[0])\n",
    "        coordinate2=str(coordinates[1])\n",
    "    else: \n",
    "        coordinate1=\"Unknown\"\n",
    "        coordinate2=\"Unknown\"\n",
    "    # saving the details into a string that we want to display later according to the format asked.\n",
    "    s=\"\\\"\"\n",
    "    s+=title\n",
    "    s+=\"\\\"\"\n",
    "    s+=\", by \"\n",
    "    s+=director\n",
    "    s+=\", from \"\n",
    "    s+=start_date\n",
    "    s+=\" to \"\n",
    "    s+=end_date\n",
    "    s+=\", in \"\n",
    "    s+=code\n",
    "    s+=\" ([\"\n",
    "    s+=coordinate1\n",
    "    s+=\", \"\n",
    "    s+=coordinate2\n",
    "    s+=\"])\"\n",
    "\n",
    "    return s\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9249e4cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:35.670903Z",
     "start_time": "2024-10-11T07:03:35.614408Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"2 Fils (Nouvelle Demande Décor Librairie / Journées interverties)\", by Félix MOATI, from 2017-10-19 to 2017-10-19, in 75011 ([2.370062415669748, 48.8696979988026])\n",
      "\"Vernon Subutex\", by Cathy Verney, from 2018-04-25 to 2018-04-26, in 75001 ([2.342487451056846, 48.85849330754624])\n",
      "\"LEBOWITZ CONTRE LEBOWITZ 2\", by Olivier Barma, from 2017-06-01 to 2017-06-01, in 75010 ([2.3646350537874703, 48.87597363622085])\n",
      "\"À jamais fidèle\", by cheyenne carron, from 2017-08-24 to 2017-08-25, in 75020 ([2.3986003434290892, 48.85154733669693])\n",
      "\"CHRONIQUES PARISIENNES 16\", by ZABOU BREITMAN, from 2017-04-18 to 2017-04-18, in 75013 ([2.3812794291774626, 48.82655664927356])\n",
      "\"LOLYWOOD - DANS TES REVES LE SPORT\", by Matthieu MARES-SAVELLI, from 2017-04-13 to 2017-04-13, in 75019 ([2.3977875069644603, 48.893005176977596])\n",
      "\"Un homme pressé\", by Hervé Mimran, from 2017-05-23 to 2017-05-24, in 75012 ([2.3691360159868426, 48.84258570428103])\n",
      "\"L'AMOUR EST UNE FÊTE\", by Cédric ANGER, from 2017-06-14 to 2017-06-14, in 75018 ([2.337097873322637, 48.882670376784226])\n",
      "\"LEBOWITZ CONTRE LEBOWITZ 2\", by [Unknown], from 2017-05-31 to 2017-05-31, in 75010 ([2.3644223583154886, 48.876569098357535])\n",
      "\"Can't Buy me love\", by Renaud Bertrand - Noémie Saglio, from 2018-05-15 to 2018-05-15, in 75009 ([2.346087705583743, 48.88227218218318])\n",
      "\"LE GENDRE IDEAL\", by Hector CABELL REYES, from 2018-05-21 to 2018-05-21, in 75010 ([2.353783961250403, 48.871601161330965])\n",
      "\"Les Affamés\", by Léa Frédeval, from 2017-07-16 to 2017-07-16, in 75008 ([2.326482985997865, 48.87278421793338])\n",
      "\"LES BEAUX ESPRITS\", by VIANNEY LEBASQUE, from 2017-07-21 to 2017-07-22, in 75010 ([2.3656441866110183, 48.876739410796205])\n",
      "\"nOX\", by mabrouk el Mechri, from 2017-07-18 to 2017-07-18, in 75020 ([2.3924234275751726, 48.8741144391816])\n",
      "\"UNDER THE EIFFEL TOWER\", by ARCHIE BORDERS, from 2017-07-18 to 2017-07-18, in 75008 ([2.3022058997720047, 48.864406963921084])\n",
      "\"Taxi 5\", by Franck Gastambide, from 2017-07-28 to 2017-07-28, in 75001 ([2.3316512810012355, 48.86314441257238])\n",
      "\"CHRONIQUES PARISIENNES\", by ZABOU BREITMAN, from 2017-04-07 to 2017-04-07, in 75010 ([2.353028536322006, 48.873991253103675])\n",
      "\"BIG BANG\", by Cécilia Rouaud, from 2017-03-29 to 2017-03-29, in 75001 ([2.3432630419377345, 48.85510452788805])\n",
      "\"THANKSGIVING\", by NICOLAS SAADA, from 2017-11-21 to 2017-11-21, in 75007 ([2.328109801855801, 48.85778012113944])\n",
      "\"CURIOSA\", by [Unknown], from 2017-11-30 to 2017-11-30, in 75116 ([2.297504389310135, 48.865760689593685])\n"
     ]
    }
   ],
   "source": [
    "# converting all entries into strings using the function display_loc that we created:\n",
    "all_entries = [display_loc(e) for e in locs]\n",
    "# Printing only the first 20 entries in the format asked:\n",
    "print('\\n'.join(all_entries[:20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e18b10d",
   "metadata": {},
   "source": [
    "- A same movie can have multiple shooting locations. Make a list of movies, where each entry contains the movie title, its director, and shootings locations (district, start date, end date).\n",
    "- How many movies do you have?\n",
    "- Write a function that converts a movie into a string that shows director, title, and shootings.\n",
    "- Convert all movies in strings.\n",
    "- Display the first 20 entries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4004bbea",
   "metadata": {},
   "source": [
    "For this question, the format of the dictionary we decided on is the following:\n",
    "\n",
    "movies = {'movie_title':{ <br>\n",
    "           'director': director_name, <br>\n",
    "           'shooting_locations': [{ 'district': district_nbr, 'start_date': start_date, 'end_date': end_date }, <br>\n",
    "           {'district': district_nbr, 'start_date': start_date, 'end_date': end_date}, <br>\n",
    "           {'district': district_nbr, 'start_date': start_date, 'end_date': end_date}, ...] <br>\n",
    "}} <br>\n",
    "Each movie title is a key and the value is a dictionary having the name of the director of the movie, and a shooting locations key where the value is an array of dictionaries of each shooting location of that movie. each shooting location has information about the district, start_date, and end_date of that shooting location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa5c9fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we created a function exists which takes as parameters a dictionary and a key. it returns true if the key exists in the dictionary, false otherwise\n",
    "def exists(dictionary, key):\n",
    "    if len(dictionary.keys())==0:\n",
    "        return False\n",
    "    for k in dictionary.keys():\n",
    "        if k==key:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d1651f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:35.675898Z",
     "start_time": "2024-10-11T07:03:35.672816Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "movies = dict()\n",
    "\n",
    "# First, we loop \"locs\", the list of dictionaries of each movie\n",
    "# An entry belongs to a movie with information about its title, director, and one shooting location where the movie took place.\n",
    "for entry in locs:\n",
    "    # From the entry get the title of the movie, the director, the district, start date and end date while placing an \"[Unknown]\" value wherever the value of the key we want is not present in the original list\n",
    "    fields=entry.get(\"fields\")\n",
    "    title=fields.get(\"nom_tournage\")\n",
    "    director= fields.get(\"nom_realisateur\", \"[Unknown]\")\n",
    "    district= fields.get(\"ardt_lieu\",\"[Unkown]\")\n",
    "    start_date= fields.get(\"date_debut\", \"[Unknown]\")\n",
    "    end_date= fields.get(\"date_fin\", \"[Unknown]\")\n",
    "    # we create a new_location dictionary which contains the values for district, start date, and end date.\n",
    "    new_location={\"district\":district, \"start_date\": start_date, \"end_date\": end_date }\n",
    "\n",
    "    # if the movie title of the entry does not exist in our movies dictionary, we want to add it in the format specified above. \n",
    "    # meaning: movie_title as the key, and values are the director, and shooting_locations array. it's an array that contains only one element, meaning one shooting location of the entry (with information about the district start date and end date),\n",
    "    # to which we will add more shooting locations later on ( after entering it in the movies dictionary first). \n",
    "    if exists(movies,title)==False:\n",
    "        # if movie title is not in our list, add it to the list for the first time.\n",
    "        shooting_locations=[]\n",
    "        shooting_locations.append(new_location)\n",
    "        movie={\n",
    "            \"director\": director,\n",
    "            \"shooting_locations\": shooting_locations\n",
    "        }          \n",
    "        movies.update({title: movie}) # this adds the key-value pair we created above to our dictionary movies.\n",
    "    else:\n",
    "        # that means the movie is already in our list and we encountered a new shooting location for that movie\n",
    "        # we need to add a new shooting location new_location to our already existing movie entry: we apend it in the movies dictionary to the shooting_locations array of THAT movie title exclusively\n",
    "        movies[title][\"shooting_locations\"].append(new_location)\n",
    "\n",
    "\n",
    "# print(movies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a934b9",
   "metadata": {},
   "source": [
    "From printing the length of the movies dictionary we created, we can see that we have 1476 different movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "245f2412",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:35.728960Z",
     "start_time": "2024-10-11T07:03:35.721811Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1476"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a4b303cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:35.740289Z",
     "start_time": "2024-10-11T07:03:35.730968Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def display_movie(movie):\n",
    "    \n",
    "    # each movie is a dictionary that has key the movie title, and value, the director name and shooting locations array.\n",
    "    # in this function, we are exclusively using the movies dictionary that we created because in the later step, we've seen that the loop is \n",
    "    # [display_movie(m) for m in movies]\n",
    "    # since movies is a dictionary, it has to have unique keys. in that case, for m in movies will loop through the keys of the movies only (which is the movie titles), instead of the values of the movies.\n",
    "    # this is why i used movies directly in the function\n",
    "\n",
    "    # getting the values of the director and shooting_locations array and creating the string having the format that is asked.\n",
    "    director=movies[movie].get(\"director\", \"[Unknown]\")\n",
    "    shootings= movies[movie].get(\"shooting_locations\") #array that we have to loop\n",
    "    s=\"\\\"\"+movie+\"\\\"\"\n",
    "    s+=\", by \"\n",
    "    s+=director\n",
    "    s+=\". Shootings: \"\n",
    "    for loc in shootings:\n",
    "        district=loc[\"district\"]\n",
    "        start_date=loc[\"start_date\"]\n",
    "        end_date=loc[\"end_date\"]\n",
    "        s+=district+\" from \"\n",
    "        s+=start_date + \" to \"\n",
    "        s+=end_date+\"; \"\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1a775b74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:35.773580Z",
     "start_time": "2024-10-11T07:03:35.753086Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"2 Fils (Nouvelle Demande Décor Librairie / Journées interverties)\", by Félix MOATI. Shootings: 75011 from 2017-10-19 to 2017-10-19; 75011 from 2017-10-19 to 2017-10-19; \n",
      "\"Vernon Subutex\", by Cathy Verney. Shootings: 75001 from 2018-04-25 to 2018-04-26; 75019 from 2018-05-22 to 2018-05-22; 75019 from 2018-05-25 to 2018-05-25; 75010 from 2018-05-03 to 2018-05-06; 75011 from 2018-03-19 to 2018-03-19; 75011 from 2018-06-01 to 2018-06-02; 75014 from 2018-06-05 to 2018-06-14; 75014 from 2018-06-13 to 2018-06-13; 75019 from 2018-05-22 to 2018-05-22; 75009 from 2018-04-11 to 2018-04-11; 75007 from 2018-06-13 to 2018-06-15; 75012 from 2018-03-23 to 2018-03-23; 75011 from 2018-04-04 to 2018-04-04; 75016 from 2018-03-30 to 2018-03-30; 75004 from 2018-03-20 to 2018-03-20; 75004 from 2018-04-26 to 2018-04-27; 75012 from 2018-08-28 to 2018-08-30; 75011 from 2018-03-19 to 2018-03-19; 75002 from 2018-03-20 to 2018-03-20; 75009 from 2018-04-09 to 2018-04-10; 75010 from 2018-08-28 to 2018-08-30; 75012 from 2018-08-28 to 2018-08-30; 75020 from 2018-04-05 to 2018-04-05; 75019 from 2018-05-21 to 2018-05-22; 75011 from 2018-05-08 to 2018-05-12; 75012 from 2018-08-28 to 2018-08-30; 75019 from 2018-05-28 to 2018-05-29; 75019 from 2018-05-30 to 2018-05-31; 75001 from 2018-04-25 to 2018-04-26; 75010 from 2018-05-31 to 2018-05-31; 75014 from 2018-06-13 to 2018-06-13; 75012 from 2018-03-23 to 2018-03-23; 75001 from 2018-04-25 to 2018-04-26; 75019 from 2018-05-24 to 2018-05-24; 75019 from 2018-05-29 to 2018-05-31; 75010 from 2018-05-31 to 2018-05-31; 75019 from 2018-05-25 to 2018-05-25; 75019 from 2018-05-22 to 2018-05-23; 75006 from 2018-04-25 to 2018-04-26; 75001 from 2018-04-25 to 2018-04-26; 75019 from 2018-05-21 to 2018-05-21; 75012 from 2018-05-02 to 2018-05-02; 75002 from 2018-05-08 to 2018-05-08; 75116 from 2018-04-16 to 2018-04-16; 75019 from 2018-05-24 to 2018-05-25; 75009 from 2018-04-09 to 2018-04-12; 75019 from 2018-05-30 to 2018-05-31; 75016 from 2018-03-30 to 2018-03-30; 75019 from 2018-05-21 to 2018-05-22; 75019 from 2018-05-29 to 2018-05-31; 75006 from 2018-04-25 to 2018-04-25; 75019 from 2018-05-24 to 2018-05-24; 75017 from 2018-05-31 to 2018-07-31; 75011 from 2018-04-06 to 2018-04-06; 75014 from 2018-06-13 to 2018-06-13; 75008 from 2018-06-13 to 2018-06-14; 75001 from 2018-06-13 to 2018-06-15; 75009 from 2018-05-31 to 2018-06-02; 75116 from 2018-04-12 to 2018-04-18; 75116 from 2018-04-12 to 2018-04-12; \n",
      "\"LEBOWITZ CONTRE LEBOWITZ 2\", by Olivier Barma. Shootings: 75010 from 2017-06-01 to 2017-06-01; 75010 from 2017-05-31 to 2017-05-31; 75010 from 2017-05-31 to 2017-05-31; 75116 from 2017-05-29 to 2017-05-29; 75010 from 2017-06-01 to 2017-06-01; 75010 from 2017-05-31 to 2017-05-31; 75116 from 2017-05-29 to 2017-05-30; 75010 from 2017-06-01 to 2017-06-01; 75010 from 2017-06-01 to 2017-06-01; 75010 from 2017-05-31 to 2017-05-31; 75010 from 2017-06-01 to 2017-06-01; 75016 from 2017-06-12 to 2017-06-12; 75010 from 2017-06-01 to 2017-06-01; 75116 from 2017-05-29 to 2017-05-29; \n",
      "\"À jamais fidèle\", by cheyenne carron. Shootings: 75020 from 2017-08-24 to 2017-08-25; 75016 from 2017-08-22 to 2017-08-22; 75020 from 2017-08-23 to 2017-08-23; 75016 from 2017-08-11 to 2017-08-11; 75016 from 2017-08-03 to 2017-08-04; 75016 from 2017-08-08 to 2017-08-08; 75011 from 2017-08-21 to 2017-08-22; 75116 from 2017-08-11 to 2017-08-11; 75020 from 2017-08-25 to 2017-08-25; 75020 from 2017-08-23 to 2017-08-24; 75016 from 2017-08-09 to 2017-08-09; 75020 from 2017-08-25 to 2017-08-25; 75016 from 2017-07-31 to 2017-07-31; 75016 from 2017-08-22 to 2017-08-23; 75016 from 2017-08-11 to 2017-08-11; 75116 from 2017-08-11 to 2017-08-11; 75116 from 2017-08-11 to 2017-08-11; 75011 from 2017-08-21 to 2017-08-21; 75020 from 2017-08-25 to 2017-08-25; 75016 from 2017-08-03 to 2017-08-04; 75020 from 2017-08-04 to 2017-08-05; 75011 from 2017-08-21 to 2017-08-22; 75016 from 2017-08-03 to 2017-08-04; 75020 from 2017-08-25 to 2017-08-25; 75016 from 2017-07-31 to 2017-07-31; 75020 from 2017-08-22 to 2017-08-22; 75116 from 2017-08-11 to 2017-08-11; 75016 from 2017-08-08 to 2017-08-08; 75016 from 2017-08-09 to 2017-08-09; 75016 from 2017-07-31 to 2017-07-31; \n",
      "\"CHRONIQUES PARISIENNES 16\", by ZABOU BREITMAN. Shootings: 75013 from 2017-04-18 to 2017-04-18; 75013 from 2017-04-18 to 2017-04-18; 75013 from 2017-04-18 to 2017-04-18; 75013 from 2017-04-18 to 2017-04-18; 75013 from 2017-04-18 to 2017-04-18; \n",
      "\"LOLYWOOD - DANS TES REVES LE SPORT\", by Matthieu MARES-SAVELLI. Shootings: 75019 from 2017-04-13 to 2017-04-13; \n",
      "\"Un homme pressé\", by Hervé Mimran. Shootings: 75012 from 2017-05-23 to 2017-05-24; 75116 from 2017-07-13 to 2017-07-14; 75116 from 2017-07-12 to 2017-07-12; 75116 from 2017-07-11 to 2017-07-12; 75015 from 2017-07-17 to 2017-07-17; 75004 from 2017-07-08 to 2017-07-09; 75005 from 2017-07-06 to 2017-07-07; 75007 from 2017-07-06 to 2017-07-06; 75116 from 2017-07-07 to 2017-07-07; 75007 from 2017-07-17 to 2017-07-17; 75017 from 2017-07-04 to 2017-07-05; 75013 from 2017-07-14 to 2017-07-14; 75013 from 2017-05-24 to 2017-05-25; 75016 from 2017-07-12 to 2017-07-12; 75013 from 2017-05-23 to 2017-05-24; 75005 from 2017-06-12 to 2017-06-12; 75116 from 2017-05-24 to 2017-05-24; 75012 from 2017-07-17 to 2017-07-18; \n",
      "\"L'AMOUR EST UNE FÊTE\", by Cédric ANGER. Shootings: 75018 from 2017-06-14 to 2017-06-14; 75009 from 2017-06-14 to 2017-06-14; 75018 from 2017-06-13 to 2017-06-13; 75018 from 2017-06-13 to 2017-06-14; 75018 from 2017-06-12 to 2017-06-13; 75018 from 2017-06-14 to 2017-06-15; \n",
      "\"Can't Buy me love\", by Renaud Bertrand - Noémie Saglio. Shootings: 75009 from 2018-05-15 to 2018-05-15; 75009 from 2018-04-10 to 2018-04-11; 75004 from 2018-04-02 to 2018-04-02; 75009 from 2018-04-04 to 2018-04-05; 75009 from 2018-05-11 to 2018-05-11; 75018 from 2018-05-15 to 2018-05-16; 75004 from 2018-05-17 to 2018-05-17; 75004 from 2018-05-17 to 2018-05-17; 75011 from 2018-03-26 to 2018-03-26; 75011 from 2018-05-08 to 2018-05-09; 75019 from 2018-05-04 to 2018-05-04; 75009 from 2018-04-04 to 2018-04-05; 75002 from 2018-05-14 to 2018-05-15; 75009 from 2018-04-11 to 2018-04-11; 75009 from 2018-04-25 to 2018-04-26; 75009 from 2018-05-15 to 2018-05-16; 75004 from 2018-04-02 to 2018-04-02; 75009 from 2018-04-28 to 2018-04-28; 75009 from 2018-05-02 to 2018-05-02; 75116 from 2018-03-19 to 2018-03-19; 75011 from 2018-03-26 to 2018-03-26; 75116 from 2018-05-09 to 2018-05-11; 75009 from 2018-05-15 to 2018-05-15; 75019 from 2018-03-28 to 2018-03-28; 75009 from 2018-03-30 to 2018-03-30; 75019 from 2018-03-28 to 2018-03-28; 75004 from 2018-05-17 to 2018-05-17; 75001 from 2018-05-18 to 2018-05-19; 75019 from 2018-03-15 to 2018-03-15; 75019 from 2018-03-15 to 2018-03-15; 75004 from 2018-04-02 to 2018-04-02; 75009 from 2018-04-27 to 2018-04-27; 75019 from 2018-03-15 to 2018-03-15; 75009 from 2018-04-23 to 2018-04-23; 75019 from 2018-05-03 to 2018-05-05; 75009 from 2018-05-16 to 2018-05-16; 75004 from 2018-05-17 to 2018-05-18; 75009 from 2018-04-12 to 2018-04-12; 75019 from 2018-03-30 to 2018-03-30; 75003 from 2018-03-20 to 2018-03-21; 75009 from 2018-04-03 to 2018-04-04; 75009 from 2018-04-04 to 2018-04-04; 75009 from 2018-04-20 to 2018-04-21; 75002 from 2018-05-14 to 2018-05-14; 75019 from 2018-03-15 to 2018-03-15; 75009 from 2018-04-04 to 2018-04-04; 75019 from 2018-03-30 to 2018-03-30; 75009 from 2018-04-03 to 2018-04-05; 75009 from 2018-04-27 to 2018-04-27; 75009 from 2018-04-25 to 2018-04-29; 75009 from 2018-04-11 to 2018-04-12; 75019 from 2018-03-28 to 2018-03-30; 75008 from 2018-05-11 to 2018-05-11; 75009 from 2018-05-16 to 2018-05-16; 75004 from 2018-05-17 to 2018-05-17; 75020 from 2018-03-16 to 2018-03-17; \n",
      "\"LE GENDRE IDEAL\", by Hector CABELL REYES. Shootings: 75010 from 2018-05-21 to 2018-05-21; 75001 from 2018-07-18 to 2018-07-20; 75010 from 2018-05-21 to 2018-05-21; 75019 from 2018-05-31 to 2018-06-01; \n",
      "\"Les Affamés\", by Léa Frédeval. Shootings: 75008 from 2017-07-16 to 2017-07-16; 75009 from 2017-06-28 to 2017-06-28; 75012 from 2017-06-09 to 2017-06-09; 75004 from 2017-06-30 to 2017-06-30; 75018 from 2017-06-08 to 2017-06-08; 75004 from 2017-06-30 to 2017-06-30; 75007 from 2017-06-20 to 2017-06-21; 75004 from 2017-06-30 to 2017-06-30; 75004 from 2017-06-30 to 2017-06-30; 75010 from 2017-07-13 to 2017-07-13; 75012 from 2017-06-09 to 2017-06-09; 75012 from 2017-06-09 to 2017-06-09; 75004 from 2017-06-30 to 2017-06-30; 75007 from 2017-05-19 to 2017-05-20; 75012 from 2017-06-06 to 2017-06-06; 75018 from 2017-06-26 to 2017-06-26; 75004 from 2017-06-30 to 2017-06-30; 75012 from 2017-06-09 to 2017-06-09; \n",
      "\"LES BEAUX ESPRITS\", by VIANNEY LEBASQUE. Shootings: 75010 from 2017-07-21 to 2017-07-22; 75010 from 2017-07-21 to 2017-07-21; 75010 from 2017-08-31 to 2017-08-31; 75010 from 2017-08-29 to 2017-08-29; 75010 from 2017-07-24 to 2017-07-25; 75014 from 2017-08-17 to 2017-08-18; 75014 from 2017-08-18 to 2017-08-19; 75013 from 2017-08-03 to 2017-08-03; 75010 from 2017-07-24 to 2017-07-24; 75015 from 2017-08-25 to 2017-08-26; 75019 from 2017-07-27 to 2017-07-27; 75010 from 2017-08-30 to 2017-08-30; \n",
      "\"nOX\", by mabrouk el Mechri. Shootings: 75020 from 2017-07-18 to 2017-07-18; \n",
      "\"UNDER THE EIFFEL TOWER\", by ARCHIE BORDERS. Shootings: 75008 from 2017-07-18 to 2017-07-18; 75007 from 2017-07-19 to 2017-07-19; 75014 from 2017-07-18 to 2017-07-18; \n",
      "\"Taxi 5\", by Franck Gastambide. Shootings: 75001 from 2017-07-28 to 2017-07-28; 75116 from 2017-07-26 to 2017-07-26; 75116 from 2017-07-25 to 2017-07-25; 75003 from 2017-07-25 to 2017-07-25; 75116 from 2017-07-27 to 2017-07-27; 75116 from 2017-07-27 to 2017-07-27; 75116 from 2017-07-27 to 2017-07-27; \n",
      "\"CHRONIQUES PARISIENNES\", by ZABOU BREITMAN. Shootings: 75010 from 2017-04-07 to 2017-04-07; 75013 from 2017-02-15 to 2017-02-15; 75013 from 2017-02-15 to 2017-02-15; 75007 from 2016-10-01 to 2016-10-01; 75004 from 2017-05-19 to 2017-05-19; 75013 from 2017-02-13 to 2017-02-13; 75013 from 2017-02-15 to 2017-02-15; 75004 from 2016-10-01 to 2016-10-01; 75006 from 2017-03-09 to 2017-03-09; 75004 from 2017-04-13 to 2017-04-13; 75019 from 2017-03-21 to 2017-03-21; 75013 from 2017-02-15 to 2017-02-15; 75008 from 2016-12-29 to 2016-12-29; 75014 from 2017-03-28 to 2017-03-28; 75004 from 2017-03-29 to 2017-03-29; 75013 from 2017-02-15 to 2017-02-15; 75009 from 2016-12-29 to 2016-12-29; 75009 from 2016-12-29 to 2016-12-29; 75010 from 2017-04-10 to 2017-04-10; 75014 from 2017-04-04 to 2017-04-04; 75010 from 2017-03-10 to 2017-03-10; 75001 from 2017-02-22 to 2017-02-22; 75001 from 2016-10-01 to 2016-10-01; 75004 from 2016-10-01 to 2016-10-01; 75015 from 2016-10-01 to 2016-10-01; 75007 from 2016-10-01 to 2016-10-01; 75013 from 2017-03-03 to 2017-03-03; 75004 from 2017-05-23 to 2017-05-24; 75010 from 2017-03-21 to 2017-03-21; 75004 from 2017-03-30 to 2017-03-30; 75004 from 2017-04-13 to 2017-04-13; 75007 from 2016-12-29 to 2016-12-29; 75007 from 2017-03-10 to 2017-03-11; 75013 from 2017-02-14 to 2017-02-14; 75001 from 2017-03-14 to 2017-03-14; 75007 from 2017-04-19 to 2017-04-20; 75001 from 2016-10-01 to 2016-10-01; 75004 from 2016-10-01 to 2016-10-01; 75008 from 2016-12-29 to 2016-12-29; 75004 from 2016-10-01 to 2016-10-01; 75001 from 2016-12-29 to 2016-12-29; 75001 from 2016-10-01 to 2016-10-01; 75001 from 2016-10-01 to 2016-10-01; 75002 from 2017-04-12 to 2017-04-12; 75003 from 2017-03-10 to 2017-03-10; 75002 from 2017-03-14 to 2017-03-14; 75007 from 2016-10-01 to 2016-10-01; 75006 from 2017-05-18 to 2017-05-18; 75008 from 2016-12-29 to 2016-12-29; 75013 from 2017-03-03 to 2017-03-03; 75016 from 2016-10-01 to 2016-10-01; 75007 from 2016-10-01 to 2016-10-01; 75010 from 2017-04-05 to 2017-04-10; 75001 from 2016-10-01 to 2016-10-01; \n",
      "\"BIG BANG\", by Cécilia Rouaud. Shootings: 75001 from 2017-03-29 to 2017-03-29; 75019 from 2017-03-22 to 2017-03-22; 75009 from 2017-03-17 to 2017-03-17; 75016 from 2017-03-27 to 2017-03-28; 75006 from 2017-03-29 to 2017-03-29; 75010 from 2017-02-22 to 2017-02-22; 75009 from 2017-03-17 to 2017-03-17; 75009 from 2017-04-10 to 2017-04-11; 75014 from 2017-03-24 to 2017-03-24; 75013 from 2017-03-01 to 2017-03-01; 75001 from 2017-03-28 to 2017-03-28; 75006 from 2017-03-24 to 2017-03-24; 75013 from 2017-03-02 to 2017-03-02; \n",
      "\"THANKSGIVING\", by NICOLAS SAADA. Shootings: 75007 from 2017-11-21 to 2017-11-21; 75010 from 2017-11-06 to 2017-11-06; 75007 from 2017-11-21 to 2017-11-21; 75008 from 2017-11-17 to 2017-11-17; 75008 from 2017-11-21 to 2017-11-21; 75012 from 2017-11-15 to 2017-11-15; 75006 from 2017-11-07 to 2017-11-07; 75007 from 2017-11-07 to 2017-11-07; 75116 from 2017-11-23 to 2017-11-23; 75008 from 2017-11-21 to 2017-11-21; 75008 from 2017-11-20 to 2017-11-20; \n",
      "\"CURIOSA\", by [Unknown]. Shootings: 75116 from 2017-11-30 to 2017-11-30; 75004 from 2017-10-24 to 2017-10-24; 75009 from 2017-11-13 to 2017-11-13; 75116 from 2017-11-30 to 2017-11-30; 75116 from 2017-11-30 to 2017-11-30; \n",
      "\"Skam\", by David Hourrègue. Shootings: 75008 from 2017-11-29 to 2017-11-29; 75004 from 2017-12-06 to 2017-12-06; 75018 from 2017-11-23 to 2017-11-23; 75012 from 2017-11-10 to 2017-11-10; 75008 from 2017-11-30 to 2017-11-30; 75004 from 2017-12-06 to 2017-12-07; 75011 from 2017-11-13 to 2017-11-13; 75012 from 2017-11-10 to 2017-11-10; 75019 from 2017-12-04 to 2017-12-04; 75011 from 2017-10-24 to 2017-10-24; 75019 from 2017-12-04 to 2017-12-04; \n"
     ]
    }
   ],
   "source": [
    "all_movie_displays = [display_movie(m) for m in movies]\n",
    "print('\\n'.join(all_movie_displays[:20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd5105a",
   "metadata": {},
   "source": [
    "- Display for each district its number of shootings. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbe44c2",
   "metadata": {},
   "source": [
    "We created an empty dictionary stats which will have keys as each distinct district present in our movies dictionary, and values as the number of times this district number appears in our movies dictionary , which is basically the number of shootings that happened in that district"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8f995e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'75011': 641,\n",
       " '75001': 722,\n",
       " '75019': 745,\n",
       " '75010': 749,\n",
       " '75014': 321,\n",
       " '75009': 642,\n",
       " '75007': 657,\n",
       " '75012': 596,\n",
       " '75016': 614,\n",
       " '75004': 670,\n",
       " '75002': 297,\n",
       " '75020': 587,\n",
       " '75006': 471,\n",
       " '75116': 421,\n",
       " '75017': 378,\n",
       " '75008': 798,\n",
       " '75013': 658,\n",
       " '75015': 363,\n",
       " '75005': 640,\n",
       " '75018': 1043,\n",
       " '75003': 236,\n",
       " '93200': 1,\n",
       " '93500': 6,\n",
       " '94320': 4,\n",
       " '92220': 1,\n",
       " '92170': 1,\n",
       " '[Unkown]': 1,\n",
       " '93320': 1,\n",
       " '93000': 1}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats=dict()\n",
    "\n",
    "for value in movies.values():\n",
    "    # we loop the shooting_locations array of each movie, and get the district of each element. \n",
    "    # if the district appears in stats, we just want to increment its value by 1\n",
    "    for loc in value['shooting_locations']:\n",
    "        district=loc[\"district\"]\n",
    "        if exists(stats, district):\n",
    "            stats[district]=stats[district]+1\n",
    "    # if the district is not in our dictionary stats, we add it along with the value 1, meaning so far it only occurred once in our movies dictionary\n",
    "        else:\n",
    "            stats[district] = 1\n",
    "\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bea5290",
   "metadata": {},
   "source": [
    "# Exercice 4 - Analyze CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d0b7b8",
   "metadata": {},
   "source": [
    "- Write a Python code retrieves the file of the most loaned titles in libraries in Paris at: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18d8464f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:35.818501Z",
     "start_time": "2024-10-11T07:03:35.808870Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type de document;Prêts 2022;Titre;Auteur;Nombre de localisations;Nombre de prêt total;Nombre d'exemplaires\r\n",
      "Bande dessinée jeunesse;1339;Astérix et la Transitalique;Ferri,  Jean-Yves;65;5221;109\r\n",
      "Bande dessinée jeunesse;1266;Sauve qui peut;Didier,  Anne;49;5015;82\r\n",
      "Bande dessinée jeunesse;1226;Astérix chez les Pictes;Ferri,  Jean-Yves;57;5766;95\r\n",
      "Bande dessinée jeunesse;1222;Max et Lili disent que c'est pas de leur faute;Saint-Mars,  Dominique de;50;4163;119\r\n",
      "Bande dessinée jeunesse;1012;Quelle \n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from requests import Session\n",
    "from io import StringIO\n",
    "\n",
    "s= Session()\n",
    "url = \"https://opendata.paris.fr/explore/dataset/les-titres-les-plus-pretes/download/?format=csv&timezone=Europe/Berlin&lang=en&use_labels_for_header=true&csv_separator=%3B\"\n",
    "\n",
    "books_loaned = s.get(url).text\n",
    "print(books_loaned[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ee78f0",
   "metadata": {},
   "source": [
    "We can note that the CSV file is separated by a \";\" between each column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cbcace",
   "metadata": {},
   "source": [
    "- Analyze the resulting CSV file to display, for all entries: title, author, and total number of loans."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb00745f",
   "metadata": {},
   "source": [
    "The CSV file contains in each line, a document or a title in a library. Each column is an information about the type of the document, the number of loans in 2022, the title of the document, the authors, the number of locations, the total number of loans, and the number of copies.\n",
    "\n",
    "To display the titles in the specific format title, author, and total number of loans, we would need from each line of the CSV file the following fields: Titre, Auteur, and Nombre de prêt total. \n",
    "\n",
    "We opened the csv file for processing using the StringIO method, read the csv file while specifying \";\" as the delimiter, and transformed it into a list of array to process it more easily. The fields we want to access are at the following indeces: 2,3, and 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a4dc52a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:36.078350Z",
     "start_time": "2024-10-11T07:03:36.075015Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def disp_book(book):\n",
    "    title=book[2]\n",
    "    author=book[3]\n",
    "    loans=book[5]\n",
    "    s=\"\\\"\"+title+\"\\\", by \"+author+\" (\"+str(loans)+\" loans)\"\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2488928b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Razzia\", by Sobral,  Patrick (2938 loans)\n",
      "\"Touche pas à mon veau\", by Guibert,  Emmanuel (2296 loans)\n",
      "\"Max et Lili vont chez papy et mamie\", by Saint-Mars,  Dominique de (5554 loans)\n",
      "\"Lili veut un petit chat\", by Saint-Mars,  Dominique de (5789 loans)\n",
      "\"Max et Lili font du camping\", by Saint-Mars,  Dominique de (5658 loans)\n",
      "\"Lili trouve sa maîtresse méchante\", by Saint-Mars,  Dominique de (4694 loans)\n",
      "\"J'irai où tu iras\", by Lyfoung,  Patricia (4707 loans)\n",
      "\"Les nerfs à vif\", by Nob (2837 loans)\n",
      "\"Je crois que je t'aime\", by Lyfoung,  Patricia (3878 loans)\n",
      "\"Attention tornade\", by Cazenove,  Christophe (2366 loans)\n",
      "\"Max et Lili se posent des questions sur Dieu\", by Saint-Mars,  Dominique de (4823 loans)\n",
      "\"Game over. 13. Toxic affair\", by Midam (2652 loans)\n",
      "\"Les Schtroumpfs et la tempête blanche\", by Jost,  Alain (975 loans)\n",
      "\"On a marché sur la lune\", by Hergé (5674 loans)\n",
      "\"Astérix chez les Bretons\", by Goscinny,  René (3014 loans)\n",
      "\"Parvati\", by Ogaki,  Philippe (2616 loans)\n",
      "\"Les Schtroumpfs et l'arbre d'or\", by Culliford,  Thierry (3460 loans)\n",
      "\"La décision : roman\", by Tuil,  Karine (976 loans)\n",
      "\"Les cahiers d'Esther. 4. Histoires de mes 13 ans\", by Sattouf,  Riad (2171 loans)\n",
      "\"Salut, les zinzins !\", by Cohen,  Jacqueline (4565 loans)\n"
     ]
    }
   ],
   "source": [
    "with StringIO(books_loaned) as csvfile:\n",
    "    r = csv.reader(csvfile, delimiter=';')\n",
    "    books = list(r) # transforming r to a list of arrays. (array of arrays because in the next code provided, we should loop firs 20 rows of books only)\n",
    "    books=books[1:] # removing the first line which is the header of the csv file from the list of arrays and keeping all the other entries of the documents.\n",
    "    print('\\n'.join( [disp_book(b) for b in books[:20]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9fa3d5",
   "metadata": {},
   "source": [
    "- Display for each type of document (there can be several entries for the same type of document), the total number of loans for this type. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da67289",
   "metadata": {},
   "source": [
    "For this part, we created a stats dictionary that has for key values each type of document we have in the CSV file. The different document types can be accessed in the books list of arrays that we created at index 0 of each array. After obtaining the type, we also store the total number of loans in a variable loans. \n",
    "We add the document type to our stats dictionary with a value = total number of loans. If the type already exists in our dictionary, we edit its value to = its current value + total number of loans of the current document array we're looping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e7ec999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bande dessinée jeunesse': 2300143,\n",
       " 'Bande dessinée ado': 29819,\n",
       " 'Livre jeunesse': 104067,\n",
       " 'Bande dessinée adulte': 59726,\n",
       " 'Livre adulte': 41731,\n",
       " 'Jeux vidéos tous publics Non prêtables': 4235,\n",
       " 'Jeux de société prêtable': 10057,\n",
       " 'Livre sonore jeunesse': 10630,\n",
       " 'DVD jeunesse': 2471,\n",
       " 'Musique jeunesse': 4792,\n",
       " 'Jeux de société': 1753}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats=dict()\n",
    "with StringIO(books_loaned) as csvfile:\n",
    "    r = csv.reader(csvfile, delimiter=';')\n",
    "    books = list(r) # transforming r to a list of arrays. (array of arrays because in the next code provided, we should loop firs 20 rows of books only)\n",
    "    books=books[1:] # removing the header elt from the list of arrays\n",
    "    for book in books:\n",
    "        type_doc=book[0] # the type is obtained from the array book\n",
    "        loans=int(book[5]) # the total number of loans of the document\n",
    "        if exists(stats, type_doc):\n",
    "            stats[type_doc]=stats[type_doc]+loans # if the type exists in stats, edit its value with its current value+total number of loans of the current document we're looping \n",
    "        else:\n",
    "            stats[type_doc] = loans # if the type does not exist in stats, add it with a value equals to the total number of loans of the current document we're looping\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b34025",
   "metadata": {},
   "source": [
    "- Display titles in order of profitability (in descending order of the number of loans per copy)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6521f8",
   "metadata": {},
   "source": [
    "In this question, We noticed that in the answer, the display contains the number of copies as well, which was not in the display_book function we created above. For that reason, we modified it to include the number of copies as well.\n",
    "\n",
    "The format now is: \"title of document\", by author (total number of loans, number of copies)\n",
    "\n",
    "We also noted that for some documents, the author name is not available, so we replaced it by [Unknown] in that case.\n",
    "\n",
    "For the sorting, we used the sorted() function and gave it a key lambda of x[5]/x[6] which is basically the total number of loans divided by the number of copies, and we sorted according to the result. The sorting was in a descending order, which is why we added the reverse=True parameter.\n",
    "\n",
    "Source: https://www.w3schools.com/python/ref_func_sorted.asp <br> https://www.freecodecamp.org/news/lambda-sort-list-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0140960b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modifying disp_book to display the copies number as well:\n",
    "def disp_book(book):\n",
    "    title=book[2]\n",
    "    author=book[3]\n",
    "    loans=book[5]\n",
    "    copies=book[6]\n",
    "    if author==\"\":\n",
    "        author=\"[Unknown]\"\n",
    "    s=\"\\\"\"+title+\"\\\", by \"+author+\" (\"+str(loans)+\" loans, \"+str(copies)+\" copies)\"\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "34e2d9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Console Nintendo Switch\", by [Unknown] (1648 loans, 2 copies)\n",
      "\"Console PlayStation 4\", by [Unknown] (2587 loans, 6 copies)\n",
      "\"SOS ouistiti :\", by [Unknown] (1868 loans, 5 copies)\n",
      "\"Quatre en ligne :\", by [Unknown] (1753 loans, 5 copies)\n",
      "\"Perplexus : : original\", by [Unknown] (2254 loans, 8 copies)\n",
      "\"Un enfant chez les schtroumpfs\", by Díaz Vizoso,  Miguel (4504 loans, 43 copies)\n",
      "\"Mon meilleur ami\", by Verron,  Laurent (4662 loans, 47 copies)\n",
      "\"Les vacances infernales\", by Cohen,  Jacqueline (5014 loans, 51 copies)\n",
      "\"Bande de sauvages !\", by Cohen,  Jacqueline (5761 loans, 60 copies)\n",
      "\"Trop, c'est trop !\", by Cohen,  Jacqueline (4504 loans, 47 copies)\n",
      "\"Les fous du mercredi\", by Cohen,  Jacqueline (5169 loans, 54 copies)\n",
      "\"Ca va chauffer !\", by Cohen,  Jacqueline (4071 loans, 44 copies)\n",
      "\"Uno :\", by [Unknown] (3136 loans, 34 copies)\n",
      "\"Ca roule !\", by Cohen,  Jacqueline (5763 loans, 63 copies)\n",
      "\"Salut, les zinzins !\", by Cohen,  Jacqueline (4565 loans, 50 copies)\n",
      "\"Les deux terreurs\", by Cohen,  Jacqueline (3999 loans, 44 copies)\n",
      "\"Subliiiimes !\", by Cohen,  Jacqueline (5007 loans, 56 copies)\n",
      "\"Un copieur sachant copier\", by Godi,  Bernard (3481 loans, 39 copies)\n",
      "\"A l'attaque !\", by Cohen,  Jacqueline (4353 loans, 49 copies)\n",
      "\"Tom-Tom et l'impossible Nana\", by Cohen,  Jacqueline (5832 loans, 66 copies)\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "with StringIO(books_loaned) as csvfile:\n",
    "    r = csv.reader(csvfile, delimiter=';')\n",
    "    books = list(r)\n",
    "    books=books[1:]\n",
    "    sorted_books=sorted(books, key= lambda x: float(x[5]) / float(x[6]), reverse=True)\n",
    "    print('\\n'.join( [disp_book(b) for b in sorted_books[:20]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10d1080",
   "metadata": {},
   "source": [
    "# Exercice 5 * - Analyze HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d24f415",
   "metadata": {},
   "source": [
    "- Write a Python program that gets the content of the Wikipedia page at: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "60cd361d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:36.180211Z",
     "start_time": "2024-10-11T07:03:36.168632Z"
    }
   },
   "outputs": [],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_by_population_density\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564d5192",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055df1a0",
   "metadata": {},
   "source": [
    "- Display all the countries mentioned in the table. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2eeac22",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e28fa638",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:36.660044Z",
     "start_time": "2024-10-11T07:03:36.649884Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Monaco',\n",
       " 'Singapore',\n",
       " 'Bahrain',\n",
       " 'Maldives',\n",
       " 'Malta',\n",
       " 'Vatican City',\n",
       " 'Bangladesh',\n",
       " 'Taiwan',\n",
       " 'Mauritius',\n",
       " 'Barbados',\n",
       " 'Nauru',\n",
       " 'San Marino',\n",
       " 'Rwanda',\n",
       " 'South Korea',\n",
       " 'Lebanon',\n",
       " 'Burundi',\n",
       " 'Tuvalu',\n",
       " 'India',\n",
       " 'Netherlands',\n",
       " 'Haiti',\n",
       " 'Israel',\n",
       " 'Philippines',\n",
       " 'Belgium',\n",
       " 'Comoros',\n",
       " 'Grenada',\n",
       " 'Sri Lanka',\n",
       " 'Japan',\n",
       " 'El Salvador',\n",
       " 'Pakistan',\n",
       " 'Trinidad and Tobago',\n",
       " 'Vietnam',\n",
       " 'Saint Lucia',\n",
       " 'United Kingdom',\n",
       " 'Saint Vincent and the Grenadines',\n",
       " 'Jamaica',\n",
       " 'Luxembourg',\n",
       " 'Liechtenstein',\n",
       " 'Gambia',\n",
       " 'Nigeria',\n",
       " 'Kuwait',\n",
       " 'São Tomé and Príncipe',\n",
       " 'Seychelles',\n",
       " 'Qatar',\n",
       " 'Germany',\n",
       " 'Dominican Republic',\n",
       " 'Marshall Islands',\n",
       " 'Malawi',\n",
       " 'North Korea',\n",
       " 'Antigua and Barbuda',\n",
       " 'Switzerland',\n",
       " 'Nepal',\n",
       " 'Uganda',\n",
       " 'Italy',\n",
       " 'Kiribati',\n",
       " 'Saint Kitts and Nevis',\n",
       " 'Andorra',\n",
       " 'Guatemala',\n",
       " 'Micronesia',\n",
       " 'Togo',\n",
       " 'Kosovo',\n",
       " 'China',\n",
       " 'Cape Verde',\n",
       " 'Isle of Man',\n",
       " 'Indonesia',\n",
       " 'Tonga',\n",
       " 'Ghana',\n",
       " 'Thailand',\n",
       " 'Denmark',\n",
       " 'Cyprus',\n",
       " 'United Arab Emirates',\n",
       " 'Transnistria',\n",
       " 'Czech Republic',\n",
       " 'Jordan',\n",
       " 'Syria',\n",
       " 'Sierra Leone',\n",
       " 'Poland',\n",
       " 'Azerbaijan',\n",
       " 'Benin',\n",
       " 'Slovakia',\n",
       " 'Ethiopia',\n",
       " 'Northern Cyprus',\n",
       " 'Egypt',\n",
       " 'Portugal',\n",
       " 'Turkey',\n",
       " 'Hungary',\n",
       " 'Austria',\n",
       " 'Iraq',\n",
       " 'Slovenia',\n",
       " 'Malaysia',\n",
       " 'Costa Rica',\n",
       " 'Cuba',\n",
       " 'Moldova',\n",
       " 'Albania',\n",
       " 'Dominica',\n",
       " 'Spain',\n",
       " 'Honduras',\n",
       " 'Cambodia',\n",
       " 'Armenia',\n",
       " 'Kenya',\n",
       " 'East Timor',\n",
       " 'Senegal',\n",
       " 'Ivory Coast',\n",
       " 'Burkina Faso',\n",
       " 'Romania',\n",
       " 'North Macedonia',\n",
       " 'Serbia',\n",
       " 'Myanmar',\n",
       " 'Samoa',\n",
       " 'Brunei',\n",
       " 'Greece',\n",
       " 'Uzbekistan',\n",
       " 'Lesotho',\n",
       " 'Tunisia',\n",
       " 'Ireland',\n",
       " 'Cook Islands',\n",
       " 'Tajikistan',\n",
       " 'Tanzania',\n",
       " 'Croatia',\n",
       " 'Ecuador',\n",
       " 'Eswatini',\n",
       " 'Mexico',\n",
       " 'Yemen',\n",
       " 'Afghanistan',\n",
       " 'Bosnia and Herzegovina',\n",
       " 'Equatorial Guinea',\n",
       " 'Ukraine',\n",
       " 'Bulgaria',\n",
       " 'Cameroon',\n",
       " 'Guinea-Bissau',\n",
       " 'Panama',\n",
       " 'Guinea',\n",
       " 'Iran',\n",
       " 'Nicaragua',\n",
       " 'Georgia',\n",
       " 'Morocco',\n",
       " 'Madagascar',\n",
       " 'Fiji',\n",
       " 'South Africa',\n",
       " 'Djibouti',\n",
       " 'Liberia',\n",
       " 'Easter Island',\n",
       " 'Belarus',\n",
       " 'Colombia',\n",
       " 'Montenegro',\n",
       " 'DR Congo',\n",
       " 'Zimbabwe',\n",
       " 'Mozambique',\n",
       " 'Lithuania',\n",
       " 'Palau',\n",
       " 'United States',\n",
       " 'Kyrgyzstan',\n",
       " 'Laos',\n",
       " 'Venezuela',\n",
       " 'Eritrea',\n",
       " 'Bahamas',\n",
       " 'Angola',\n",
       " 'Somaliland',\n",
       " 'Estonia',\n",
       " 'Somalia',\n",
       " 'Latvia',\n",
       " 'Abkhazia',\n",
       " 'Vanuatu',\n",
       " 'Zambia',\n",
       " 'Sudan',\n",
       " 'Peru',\n",
       " 'Chile',\n",
       " 'Solomon Islands',\n",
       " 'Brazil',\n",
       " 'Sweden',\n",
       " 'Papua New Guinea',\n",
       " 'Niger',\n",
       " 'Bhutan',\n",
       " 'Uruguay',\n",
       " 'New Zealand',\n",
       " 'Algeria',\n",
       " 'Mali',\n",
       " 'Belize',\n",
       " 'Congo',\n",
       " 'South Sudan',\n",
       " 'Saudi Arabia',\n",
       " 'Finland',\n",
       " 'Argentina',\n",
       " 'South Ossetia',\n",
       " 'Paraguay',\n",
       " 'Oman',\n",
       " 'Chad',\n",
       " 'Norway',\n",
       " 'Turkmenistan',\n",
       " 'Bolivia',\n",
       " 'Central African Republic',\n",
       " 'Gabon',\n",
       " 'Russia',\n",
       " 'Niue',\n",
       " 'Kazakhstan',\n",
       " 'Mauritania',\n",
       " 'Botswana',\n",
       " 'Libya',\n",
       " 'Canada',\n",
       " 'Suriname',\n",
       " 'Guyana',\n",
       " 'Iceland',\n",
       " 'Australia',\n",
       " 'Namibia',\n",
       " 'Mongolia']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c01c83",
   "metadata": {},
   "source": [
    "- Display for each country its rank, density, population, area. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a0d576",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08543386",
   "metadata": {},
   "source": [
    "- Save the information obtained in a Python dictionary. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea033867",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043b4f22",
   "metadata": {},
   "source": [
    "- Using the previously saved Python dictionary, ask the user for a country, display the \n",
    "corresponding information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571931a2",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cba0977",
   "metadata": {},
   "source": [
    "# Exercice 6 * - API Web"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ecf35c",
   "metadata": {},
   "source": [
    "- Write a Python program that will make available a Web API allowing elementary calculations on \n",
    "integers.\n",
    "\n",
    "The APIs are accessible by GET and in the form: \n",
    "- /add/{integer1}/{integer2}: add integer1 and integer2\n",
    "- /sub/{integer1}/{integer2}: perform the subtraction of integer1 and integer2\n",
    "- /mul/{integer1}/{integer2}: carry out the multiplication of integer1 and integer2\n",
    "- /div/{integer1}/{integer2}: perform the integer division of integer1 by integer2\n",
    "- /mod/{integer1}/{integer2}: perform the remainder of the integer division of integer1\n",
    "by integer2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c4ce27",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d0339059",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:46.583700Z",
     "start_time": "2024-10-11T07:03:36.825290Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://localhost:8080\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [11/Oct/2024 09:03:41] \"GET /mod/42/8 HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "app.run(host='localhost', port=8080)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9763e3",
   "metadata": {},
   "source": [
    "http://localhost:8080/mul/6/7\n",
    "\n",
    "http://localhost:8080/div/42/8\n",
    "\n",
    "http://localhost:8080/mod/42/8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27afa0c",
   "metadata": {},
   "source": [
    "- Write a Python program that will test the web API made available through the requests\n",
    "library. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be889bfb",
   "metadata": {},
   "source": [
    "Answer"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
